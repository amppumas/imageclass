from os.path import exists, join
from os import remove
from keras.optimizers import rmsprop
from keras.preprocessing.image import ImageDataGenerator
from keras.utils import to_categorical
from keras.models import Sequential
from keras.layers import Dense, Dropout, Activation, Flatten
from keras.layers import Conv2D, MaxPooling2D
from .loadFunctions import loadAndCreateDataset, createDirs
from pickle import load, dump


class LogoOrCifar:
    def __init__(self, train_sz=150000, cifar_len=0, lld_len=50000):

        self.cifar_len = cifar_len
        self.lld_len = lld_len
        self.model_name = 'cifar_' + str(cifar_len) + '_lld_' + str(lld_len)

        images, labels = self.loadData()

        self.x_train = images[:train_sz]
        self.y_train = to_categorical(labels[:train_sz], 2)
        test_sz = len(labels) - train_sz
        self.x_test = images[:-test_sz]
        self.y_test = to_categorical(labels[:-test_sz], 2)

        self.model = None
        self.model_path = ''

    def loadData(self):
        dataset_path = 'datasets/processed/' + self.model_name + '_dataset.pkl'

        if exists(dataset_path):
            print('Dataset already exists, loading...')
            with open(dataset_path, 'rb') as f:
                images, labels = load(f, encoding='bytes')
        else:
            createDirs('datasets/processed/')
            images, labels = loadAndCreateDataset(self.cifar_len, self.lld_len)
            if self.lld_len != 0:
                print('Saving dataset in', dataset_path)
                with open(dataset_path, 'wb') as f:
                    try:
                        dump((images, labels), f)
                    except (MemoryError, OverflowError):
                        remove(dataset_path)
                        print('ERROR: Not enough memory to save dataset')

        return images, labels

    def defineModel(self, conv=2, flat=512):
        model = Sequential()
        model.add(Conv2D(32, (3, 3), padding='same', input_shape=self.x_train.shape[1:]))
        model.add(Activation('relu'))
        model.add(Conv2D(32, (3, 3)))
        model.add(Activation('relu'))
        model.add(MaxPooling2D(pool_size=(2, 2)))
        model.add(Dropout(0.25))

        model.add(Conv2D(64, (3, 3), padding='same'))
        model.add(Activation('relu'))
        model.add(Conv2D(64, (3, 3)))
        model.add(Activation('relu'))
        model.add(MaxPooling2D(pool_size=(2, 2)))
        model.add(Dropout(0.25))

        if conv == 3:
            model.add(Conv2D(96, (3, 3), padding='same'))
            model.add(Activation('relu'))
            model.add(Conv2D(96, (3, 3)))
            model.add(Activation('relu'))
            model.add(Dropout(0.25))

        model.add(Flatten())
        model.add(Dense(flat))
        model.add(Activation('relu'))
        #model.add(Dropout(0.5))
        model.add(Dense(2))
        model.add(Activation('softmax'))
        self.model = model
        self.model_name += '_flat_' + str(flat) + '_conv_' + str(conv) + '.h5'
        # Save model and weights
        self.model_path = join(createDirs('saved_models'), self.model_name)
        if not exists(self.model_path):
            return self.initializeModel()
        else:
            print('Model has been trained')
            return False

    def initializeModel(self):

        # initiate RMSprop optimizer
        opt = rmsprop(lr=0.0001, decay=1e-6)

        # Let's train the model using RMSprop
        self.model.compile(loss='categorical_crossentropy',
                           optimizer=opt,
                           metrics=['accuracy'])

        self.x_train /= 255
        self.x_test /= 255

        return True

    def fitToData(self, batch_size=32, epochs=1):
        # This will do preprocessing and realtime data augmentation:
        datagen = ImageDataGenerator(
            featurewise_center=True,  # set input mean to 0 over the dataset
            samplewise_center=False,  # set each sample mean to 0
            featurewise_std_normalization=True,  # divide inputs by std of the dataset
            samplewise_std_normalization=False,  # divide each input by its std
            zca_whitening=False,  # apply ZCA whitening,
            rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)
            width_shift_range=0,  # randomly shift images horizontally (fraction of total width)
            height_shift_range=0,  # randomly shift images vertically (fraction of total height)
            horizontal_flip=False,  # randomly flip images
            vertical_flip=False)  # randomly flip images

        datagen.fit(self.x_train)

        # Fit the model on the batches generated by datagen.flow().
        self.model.fit_generator(datagen.flow(self.x_train, self.y_train,
                                              batch_size=batch_size),
                                 epochs=epochs,
                                 validation_data=(self.x_test, self.y_test),
                                 workers=4,
                                 verbose=1)

        self.model.save(self.model_path)
        print('Saved trained model at', self.model_path)
